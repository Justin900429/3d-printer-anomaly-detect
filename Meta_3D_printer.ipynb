{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Meta learning for 3D printer dataset\n",
        "* [dataset](https://www.kaggle.com/datasets/justin900429/3d-printer-defected-dataset)\n",
        "> This notebook is mainly adapted from [Open AI work](https://github.com/gabrielhuang/reptile-pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6AcReMXnjnE",
        "outputId": "e4885d1c-01bc-4525-f9e0-0e0f59cc5d1a"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!pip install gdown==4.4.0\n",
        "!gdown 1Fq0DkvzoB3wI6a8IgPeYplD01c-WmXvn -O tmp.zip && unzip -q tmp.zip && rm tmp.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1B6ozRKoZBS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm \n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91dy0zCCoQUQ"
      },
      "source": [
        "## Creat training and testing validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpJ4-A3CoU8o"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "\n",
        "# Set up training dataset\n",
        "train_no_defect = [\n",
        "    file for file in glob.glob(\"no_defected/*.jpg\") if \"scratch_2\" not in file]\n",
        "train_yes_defect = [\n",
        "    file for file in glob.glob(\"defected/*.jpg\") if \"no_bottom\" not in file\n",
        "]\n",
        "train_yes_defect = random.choices(train_yes_defect, k=len(train_no_defect))\n",
        "\n",
        "# Set up validation dataset\n",
        "val_no_defect = [\n",
        "    file for file in glob.glob(\"no_defected/*.jpg\") if \"scratch_2\" in file]\n",
        "val_yes_defect = [\n",
        "    file for file in glob.glob(\"defected/*.jpg\") if \"no_bottom\" in file]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnuShA8zfS0n"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6079R3QnfVTa"
      },
      "outputs": [],
      "source": [
        "# Count the number of the the class\n",
        "# Training\n",
        "count_train_no_defect = len(train_no_defect)\n",
        "count_train_defect = len(train_yes_defect)\n",
        "\n",
        "# Validation\n",
        "count_val_no_defect = len(val_no_defect)\n",
        "count_val_defect = len(val_yes_defect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "S9vC2avXjDHw",
        "outputId": "f123df41-ea11-4a64-b0fe-6c39931465e3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Set up title and and x label\n",
        "x_title = [\"training\", \"validation\"]\n",
        "no_defect_score = [count_train_no_defect, count_val_no_defect]\n",
        "defect_score = [count_train_defect, count_val_defect]\n",
        "x = np.arange(len(x_title))\n",
        "width = 0.3\n",
        "\n",
        "# Plot the data\n",
        "bar1 = ax.bar(x, no_defect_score, width, color=\"#D67D3E\", label=\"no defect\")\n",
        "bar2 = ax.bar(x + width, defect_score, width, color=\"#F9E4D4\", label=\"defect\")\n",
        "\n",
        "# Add heights above the bar plot\n",
        "for rect, height in zip(bar1 + bar2, no_defect_score + defect_score):\n",
        "    height = rect.get_height()\n",
        "    plt.text(\n",
        "        rect.get_x() + rect.get_width() / 2.0, height + 2,\n",
        "        f\"{height:.0f}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "# Beautify the plot (optional)\n",
        "ax.set_xticks(x + width / 2)\n",
        "ax.set_xticklabels(x_title)\n",
        "ax.set_yticks([])\n",
        "ax.set_title(\"Distribution of dataset\")\n",
        "ax.spines[\"right\"].set_visible(False)\n",
        "ax.spines[\"top\"].set_visible(False)\n",
        "ax.spines[\"left\"].set_visible(False)\n",
        "\n",
        "# Show the annotation to each bar\n",
        "plt.legend()\n",
        "plt.savefig(\"data.pdf\", transparent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ku3Qa9VXXLm",
        "outputId": "9ccce21b-2080-4ccf-a5c6-a3ab584e2670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guess all yes defect 0.1979381443298969\n",
            "Guess all no defect 0.42961876832844575\n"
          ]
        }
      ],
      "source": [
        "# 0.75 no for acc\n",
        "# Guess all samples to be 1 (yes defect)\n",
        "print(\"Guess all yes defect\",\n",
        "      f1_score([0]*count_val_no_defect + [1]*count_val_defect, [1] * (count_val_no_defect + count_val_defect), average=\"macro\"))\n",
        "# Guess all samples to be 0 (no defect)\n",
        "print(\"Guess all no defect\", \n",
        "      f1_score([0]*count_val_no_defect + [1]*count_val_defect, [0]*(count_val_no_defect + count_val_defect), average=\"macro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5MeSYQ7rQjJ"
      },
      "source": [
        "## Create Meta Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPfwPPyAqj3D"
      },
      "outputs": [],
      "source": [
        "class FewShotDataset(Dataset):\n",
        "    def __init__(self, img_list, transform):\n",
        "        self.img_list = img_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        label, path = self.img_list[idx]\n",
        "        img = Image.open(path)\n",
        "        img = self.transform(img)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Nlo8bYj7_n"
      },
      "outputs": [],
      "source": [
        "class MetaPrinterFolder:\n",
        "    def __init__(self, no_defect, yes_defect, \n",
        "                 train_transform=None, val_transform=None):\n",
        "        self.no_defect = no_defect\n",
        "        self.yes_defect = yes_defect\n",
        "        self.train_transform = train_transform\n",
        "        self.val_transform = val_transform\n",
        "        \n",
        "    def get_random_task(self, K=1):\n",
        "        train_task, _ = self.get_random_task_split(train_K=K, test_K=0)\n",
        "        return train_task\n",
        "\n",
        "    def get_random_task_split(self, train_K=1, test_K=1):\n",
        "        train_samples = []\n",
        "        test_samples = []\n",
        "        \n",
        "        sample_num = train_K + test_K\n",
        "        # ====== Good list =======\n",
        "        for idx, path in enumerate(np.random.choice(self.no_defect, sample_num, \n",
        "                                                    replace=False)):\n",
        "            if idx < train_K:\n",
        "                train_samples.append((0, path))\n",
        "            else:\n",
        "                test_samples.append((0, path))\n",
        "\n",
        "        # ====== Bad list =======\n",
        "        for i, path in enumerate(np.random.choice(self.yes_defect, sample_num, \n",
        "                                                  replace=False)):\n",
        "            if i < train_K:\n",
        "                train_samples.append((1, path))\n",
        "            else:\n",
        "                test_samples.append((1, path))\n",
        "\n",
        "        train_task = FewShotDataset(train_samples, self.train_transform)\n",
        "        test_task = FewShotDataset(test_samples, self.val_transform)\n",
        "                             \n",
        "        return train_task, test_task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKyBgMukrKvZ"
      },
      "outputs": [],
      "source": [
        "demo_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((400, 400)),\n",
        "    transforms.CenterCrop((352, 352)),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        " \n",
        "meta_3d_printer = MetaPrinterFolder(\n",
        "    train_no_defect, train_yes_defect, demo_transform, demo_transform)\n",
        "train_task = meta_3d_printer.get_random_task()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owLz-qPcc3So"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOx_RL_mc5ME"
      },
      "outputs": [],
      "source": [
        "class ReptileModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def point_grad_to(self, target):\n",
        "        self.zero_grad()\n",
        "        for p, target_p in zip(self.parameters(), target.parameters()):\n",
        "            if p.grad is None:\n",
        "                if self.is_cuda():\n",
        "                    p.grad = torch.zeros(p.size()).cuda()\n",
        "                else:\n",
        "                    p.grad = torch.zeros(p.size())\n",
        "            p.grad.data.add_(p.data - target_p.data)\n",
        "\n",
        "    def is_cuda(self):\n",
        "        return next(self.parameters()).is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adAvF4PcdHLd"
      },
      "outputs": [],
      "source": [
        "class TrainModel(ReptileModel):\n",
        "    def __init__(self, model_name=\"resnet34\", pretrained=True, num_classes=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Model settings\n",
        "        self.model_name = model_name\n",
        "        self.pretrained=pretrained\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Check out the doc: https://rwightman.github.io/pytorch-image-models/\n",
        "        #  for different models\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        \n",
        "        # Change the output linear layers to fit the output classes\n",
        "        self.model.fc = nn.Linear(\n",
        "            self.model.fc.weight.shape[1],\n",
        "            num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def clone(self):\n",
        "        clone = TrainModel(self.model_name, self.pretrained, self.num_classes)\n",
        "        clone.load_state_dict(self.state_dict())\n",
        "        if self.is_cuda():\n",
        "            clone.cuda()\n",
        "        return clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIypzX3lsimZ"
      },
      "source": [
        "## Set up training pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htm7Q1SRsmQJ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader, args):\n",
        "    model.eval()\n",
        "\n",
        "    total_predict = []\n",
        "    total_ground_truth = []\n",
        "    for iteration in range(args.iterations):\n",
        "        data, label = val_loader.__next__()\n",
        "        data = data.to(args.device)\n",
        "        label = label.to(args.device)\n",
        "\n",
        "        output = model(data)\n",
        "        prediction = output.argmax(dim=-1)\n",
        "\n",
        "        total_predict.extend(prediction.cpu().tolist())\n",
        "        total_ground_truth.extend(label.cpu().tolist())\n",
        "\n",
        "    return accuracy_score(total_ground_truth, total_predict), \\\n",
        "           f1_score(total_ground_truth, total_predict, average=\"macro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtAbMcfKsiO8"
      },
      "outputs": [],
      "source": [
        "def train_iter(model, train_loader, criterion, optimizer, args):\n",
        "    model.train()\n",
        "    for iteration in range(args.iterations):\n",
        "        data, label = train_loader.__next__()\n",
        "        data = data.to(args.device)\n",
        "        label = label.to(args.device)\n",
        "\n",
        "        # Send data into the model and compute the loss\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        # Update the model with back propagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaSgvXrztVct"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(net, args, state=None):\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
        "    if state is not None:\n",
        "        optimizer.load_state_dict(state)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CyTWpW5tbf5"
      },
      "outputs": [],
      "source": [
        "def set_learning_rate(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdx3big2_Q0I"
      },
      "outputs": [],
      "source": [
        "def make_infinite(dataloader):\n",
        "    while True:\n",
        "        for x in dataloader:\n",
        "            yield x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvI81fJD-Y6M"
      },
      "outputs": [],
      "source": [
        "def meta_train_reptile(args, meta_model, meta_train, meta_test, meta_optimizer, criterion):\n",
        "    for meta_iteration in tqdm(range(args.start_meta_iteration, args.meta_iterations)):\n",
        "        # Update learning rate\n",
        "        meta_lr = args.meta_lr * (1. - meta_iteration / float(args.meta_iterations))\n",
        "        set_learning_rate(meta_optimizer, meta_lr)\n",
        "\n",
        "        # Clone model\n",
        "        net = meta_model.clone()\n",
        "        optimizer = get_optimizer(net, args)\n",
        "\n",
        "        # Sample base task from Meta-Train\n",
        "        train_dataset = meta_train.get_random_task(args.train_shots)\n",
        "        infinite_train_loader = make_infinite(\n",
        "            DataLoader(\n",
        "                train_dataset, args.batch_size, shuffle=True,\n",
        "                num_workers=2, pin_memory=True))\n",
        "\n",
        "        # Update fast net\n",
        "        train_iter(net, infinite_train_loader, criterion, optimizer, args)\n",
        "\n",
        "        # Update slow net\n",
        "        meta_model.point_grad_to(net)\n",
        "        meta_optimizer.step()\n",
        "\n",
        "        # Meta-Evaluation\n",
        "        if meta_iteration % args.validate_every == 0:\n",
        "            for (meta_dataset, mode) in [(meta_test, \"val\")]:\n",
        "                train, test = meta_dataset.get_random_task_split(\n",
        "                    train_K=args.shots, test_K=5)\n",
        "                infinite_train_loader = make_infinite(\n",
        "                    DataLoader(\n",
        "                        train, args.batch_size, shuffle=True,\n",
        "                        num_workers=2, pin_memory=True))\n",
        "                infinite_test_loader = make_infinite(\n",
        "                    DataLoader(\n",
        "                        test, args.batch_size, shuffle=True,\n",
        "                        num_workers=2, pin_memory=True))\n",
        "\n",
        "                # Base-train\n",
        "                net = meta_model.clone()\n",
        "                optimizer = get_optimizer(net, args)\n",
        "                train_iter(\n",
        "                    net, infinite_train_loader, criterion, optimizer, args)\n",
        "\n",
        "                # Base-test: compute meta-loss, which is base-validation error\n",
        "                meta_acc, meta_f1 = evaluate(net, infinite_test_loader, args)\n",
        "                print(f\"\\n{mode}: f1-accuracy: {meta_f1:.3f}, acc: {meta_acc:.3f}\")\n",
        "\n",
        "        if meta_iteration % args.check_every == 0:\n",
        "            torch.save(meta_model.state_dict(), \"cur.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mep71RznuRvb"
      },
      "source": [
        "## Combine all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLfa3vuLruxq"
      },
      "outputs": [],
      "source": [
        "class args:\n",
        "    # Training\n",
        "    epochs = 30\n",
        "    batch_size = 32\n",
        "    train_shots = 10\n",
        "    shots = 5\n",
        "    meta_iterations = 1000\n",
        "    start_meta_iteration = 0\n",
        "    iterations = 5\n",
        "    test_iterations = 50\n",
        "    meta_lr = 0.1\n",
        "    validate_every = 20\n",
        "    check_every = 100\n",
        "    lr = 3e-4\n",
        "    weight_decay=1e-5\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Transform\n",
        "    size = 400\n",
        "    crop_size = 352\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVIpM7cFCros"
      },
      "outputs": [],
      "source": [
        "# Set up train loader and test loader\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((args.size, args.size)),\n",
        "    transforms.CenterCrop((args.crop_size, args.crop_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Normalize(mean=args.mean, std=args.std)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                                    \n",
        "    transforms.Resize((args.size, args.size)),\n",
        "    transforms.CenterCrop((args.crop_size, args.crop_size)),\n",
        "    transforms.Normalize(mean=args.mean, std=args.std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNGkRNBaCtXw",
        "outputId": "b6a44b82-e1d9-4f2c-a9ac-e8c02a947cd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n"
          ]
        }
      ],
      "source": [
        "# Set up model\n",
        "meta_model = TrainModel().to(args.device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "meta_optimizer = torch.optim.SGD(\n",
        "    meta_model.parameters(), lr=args.meta_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugh-_rXWIId3"
      },
      "outputs": [],
      "source": [
        "meta_train = MetaPrinterFolder(\n",
        "    train_no_defect, train_yes_defect, train_transform, val_transform)\n",
        "meta_test = MetaPrinterFolder(\n",
        "    val_no_defect, val_yes_defect, train_transform, val_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnO6Wd8rITCE",
        "outputId": "132b1a9a-2dde-4487-f4e2-8e31bbbbe957"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1000 [00:06<1:49:06,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 1.000, acc: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 21/1000 [01:08<1:03:05,  3.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 1.000, acc: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 41/1000 [02:09<1:01:38,  3.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 1.000, acc: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 61/1000 [03:12<1:02:17,  3.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 81/1000 [04:15<1:01:51,  4.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 100/1000 [05:11<43:42,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 121/1000 [06:21<59:02,  4.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 141/1000 [07:22<55:55,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 161/1000 [08:25<54:51,  3.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 181/1000 [09:27<54:11,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.899, acc: 0.900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 200/1000 [10:24<39:27,  2.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 221/1000 [11:34<51:55,  4.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 241/1000 [12:38<51:03,  4.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 261/1000 [13:42<50:31,  4.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 281/1000 [14:48<48:50,  4.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 300/1000 [15:46<36:01,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 321/1000 [16:57<46:12,  4.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 341/1000 [18:03<45:37,  4.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 361/1000 [19:09<45:00,  4.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 381/1000 [20:14<42:56,  4.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 1.000, acc: 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 400/1000 [21:14<31:39,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 421/1000 [22:27<40:30,  4.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 441/1000 [23:35<39:29,  4.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 461/1000 [24:41<38:06,  4.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 481/1000 [25:50<37:56,  4.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 500/1000 [26:51<27:11,  3.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 521/1000 [28:05<34:35,  4.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 541/1000 [29:14<33:58,  4.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 561/1000 [30:24<32:06,  4.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 581/1000 [31:34<30:48,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 600/1000 [32:35<21:31,  3.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 621/1000 [33:54<28:25,  4.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 641/1000 [35:03<26:41,  4.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 661/1000 [36:15<25:32,  4.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 681/1000 [37:26<24:33,  4.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 700/1000 [38:30<16:31,  3.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 721/1000 [39:49<21:24,  4.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.899, acc: 0.900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 741/1000 [41:00<19:42,  4.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 761/1000 [42:14<18:52,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 781/1000 [43:26<16:48,  4.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 800/1000 [44:30<11:16,  3.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 821/1000 [45:52<14:39,  4.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.333, acc: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 841/1000 [47:05<12:35,  4.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 861/1000 [48:19<10:55,  4.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 881/1000 [49:31<09:16,  4.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 900/1000 [50:38<05:50,  3.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 921/1000 [51:59<06:12,  4.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.792, acc: 0.800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 941/1000 [53:13<04:40,  4.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.670, acc: 0.700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 961/1000 [54:27<03:06,  4.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.524, acc: 0.600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 981/1000 [55:44<01:39,  5.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "val: f1-accuracy: 0.899, acc: 0.900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [56:51<00:00,  3.41s/it]\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "meta_train_reptile(args, meta_model, meta_train, meta_test, meta_optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvTwp9G5f-wA"
      },
      "source": [
        "## Used pretrained network to train on the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ6aBFgUf-Ox"
      },
      "outputs": [],
      "source": [
        "class ListDataset(Dataset):\n",
        "    def __init__(self, yes_defect, no_defect, transform=None):\n",
        "        self.img_list = yes_defect + no_defect\n",
        "        self.label = [1] * len(yes_defect) + [0] * len(no_defect)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_list[idx])\n",
        "        label = self.label[idx]\n",
        "        img = self.transform(img)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QORqXvUTgQj0"
      },
      "outputs": [],
      "source": [
        "def make_loader(yes_defect, no_defect, transform, batch_size,\n",
        "                shuffle=True, num_workers=2, pin_memory=True,\n",
        "                train=True):\n",
        "    dataset = ListDataset(\n",
        "        yes_defect=yes_defect, no_defect=no_defect, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        dataset, batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=pin_memory)\n",
        "    \n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYKD7kFbgj6O"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def post_train_evaluate(model, val_loader, args):\n",
        "    model.eval()\n",
        "\n",
        "    total_predict = []\n",
        "    total_ground_truth = []\n",
        "    for data, label in val_loader:\n",
        "        data = data.to(args.device)\n",
        "        label = label.to(args.device)\n",
        "\n",
        "        output = model(data)\n",
        "        prediction = output.argmax(dim=-1)\n",
        "\n",
        "        total_predict.extend(prediction.cpu().tolist())\n",
        "        total_ground_truth.extend(label.cpu().tolist())\n",
        "\n",
        "    return accuracy_score(total_ground_truth, total_predict), \\\n",
        "           f1_score(total_ground_truth, total_predict, average=\"macro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpC_XmgNglyx"
      },
      "outputs": [],
      "source": [
        "def post_train(model, train_loader, val_loader, criterion, optimizer, args):\n",
        "    best_f1 = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        train_progress_bar = tqdm(\n",
        "            train_loader, desc=f\"Epochs: {epoch + 1}/{args.epochs}\")\n",
        "        \n",
        "        model.train()\n",
        "        for data, label in train_progress_bar:\n",
        "            data = data.to(args.device)\n",
        "            label = label.to(args.device)\n",
        "\n",
        "            # Send data into the model and compute the loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            # Update the model with back propagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Compute the accuracy ans save the best model\n",
        "        eval_acc, eval_f1 = post_train_evaluate(model, val_loader, args)\n",
        "        print(f\"Validation accuracy: {eval_acc:.8f} f1-score: {eval_f1:.8f}\")\n",
        "        if eval_f1 > best_f1:\n",
        "            best_f1 = eval_f1\n",
        "            torch.save(model.state_dict(), \"best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYb2Cw6igcEQ"
      },
      "outputs": [],
      "source": [
        "train_loader = make_loader(\n",
        "    yes_defect=train_yes_defect, no_defect=train_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=train_transform)\n",
        "val_loader = make_loader(\n",
        "    yes_defect=val_yes_defect, no_defect=val_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=val_transform, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_te_psxfzw3"
      },
      "outputs": [],
      "source": [
        "meta_model.load_state_dict(torch.load(\"cur.pt\"))\n",
        "train_model = meta_model.clone()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_optimizer = torch.optim.Adam(train_model.parameters(), lr=args.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs5PeIH6gi4S",
        "outputId": "6dd77ae2-b3f6-4cd2-c57c-d8eb99772a9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 1/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 2/30: 100%|██████████| 32/32 [00:10<00:00,  3.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 3/30: 100%|██████████| 32/32 [00:10<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 4/30: 100%|██████████| 32/32 [00:10<00:00,  3.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 5/30: 100%|██████████| 32/32 [00:10<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 6/30: 100%|██████████| 32/32 [00:10<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 7/30: 100%|██████████| 32/32 [00:10<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 8/30: 100%|██████████| 32/32 [00:10<00:00,  3.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 9/30: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 10/30: 100%|██████████| 32/32 [00:10<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 11/30: 100%|██████████| 32/32 [00:10<00:00,  3.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 12/30: 100%|██████████| 32/32 [00:10<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 13/30: 100%|██████████| 32/32 [00:10<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 14/30: 100%|██████████| 32/32 [00:10<00:00,  3.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 15/30: 100%|██████████| 32/32 [00:10<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 16/30: 100%|██████████| 32/32 [00:10<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 17/30: 100%|██████████| 32/32 [00:10<00:00,  3.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 18/30: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 19/30: 100%|██████████| 32/32 [00:10<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 20/30: 100%|██████████| 32/32 [00:10<00:00,  3.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 21/30: 100%|██████████| 32/32 [00:14<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 22/30: 100%|██████████| 32/32 [00:10<00:00,  3.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 23/30: 100%|██████████| 32/32 [00:10<00:00,  3.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 24/30: 100%|██████████| 32/32 [00:10<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 25/30: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 26/30: 100%|██████████| 32/32 [00:11<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 27/30: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 28/30: 100%|██████████| 32/32 [00:10<00:00,  3.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 29/30: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 30/30: 100%|██████████| 32/32 [00:10<00:00,  2.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.0000 f1-score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "post_train(train_model, train_loader, val_loader, criterion, train_optimizer, args)\n",
        "torch.save(train_model.state_dict(), \"last.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D0hKqFmrOXN"
      },
      "source": [
        "## Model Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tu2hBz5ywOP"
      },
      "outputs": [],
      "source": [
        "class GradCAM:\n",
        "    def __init__(self, model, layer_name, img_size):\n",
        "        self.model = model\n",
        "        self.layer_name = layer_name\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Save the forward and backward features\n",
        "        self.module_list = []\n",
        "        self.features_list = dict()\n",
        "        self.gradient_list = dict()\n",
        "\n",
        "        # Handlers list\n",
        "        self.handlers = []\n",
        "        self._register_hook()\n",
        "\n",
        "        self.img_transform =  transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((400, 400)),\n",
        "            transforms.CenterCrop((img_size, img_size)),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "\n",
        "    def activation_name(self, name, hook_type):\n",
        "        def _get_hook(module, input, output):\n",
        "            if hook_type == \"forward\":\n",
        "                self.module = name\n",
        "                self.features_list[name] = output\n",
        "            elif hook_type == \"backward\":\n",
        "                self.gradient_list[name] = output[0]\n",
        "            else:\n",
        "                raise ValueError(f\"Nor supported hook type: {hook_type}\")\n",
        "        return _get_hook\n",
        "\n",
        "    def _clear_list(self):\n",
        "        self.module = None\n",
        "        self.features_list = dict()\n",
        "        self.gradient_list = dict()\n",
        "\n",
        "    def _register_hook(self):\n",
        "        self.handlers = []\n",
        "        for (name, module) in self.model.named_modules():\n",
        "            if name == self.layer_name:\n",
        "                self.handlers.append(\n",
        "                    module.register_forward_hook(\n",
        "                        self.activation_name(name, \"forward\")\n",
        "                    )\n",
        "                )\n",
        "                self.handlers.append(\n",
        "                    module.register_full_backward_hook(\n",
        "                        self.activation_name(name, \"backward\")\n",
        "                    )\n",
        "                )\n",
        "    \n",
        "    def remove_handlers(self):\n",
        "        for handle in self.handlers:\n",
        "            handle.remove()\n",
        "\n",
        "    def __call__(self, img, device):\n",
        "        # Clear the list\n",
        "        self._clear_list()\n",
        "\n",
        "        ori_size = img.shape[:2][::-1]\n",
        "        in_features = self.img_transform(img).to(device)\n",
        "        \n",
        "        res = self.model(in_features.unsqueeze(0)).view(-1)\n",
        "        \n",
        "        self.model.zero_grad()\n",
        "        predict_cls = res.argmax(dim=-1).item()\n",
        "        target = res[predict_cls]\n",
        "        target.backward()\n",
        "\n",
        "        gradient = self.gradient_list[self.module].data[0]\n",
        "        weight = torch.mean(gradient, dim=(1, 2), keepdim=True)\n",
        "\n",
        "        feature = self.features_list[self.module].data[0]\n",
        "        temp_cam = (feature * weight).sum(dim=0).relu()\n",
        "\n",
        "        # Normalize the value\n",
        "        temp_cam -= torch.min(temp_cam)\n",
        "        temp_cam /= torch.max(temp_cam)\n",
        "\n",
        "        temp_cam = cv2.resize(\n",
        "            temp_cam.detach().cpu().numpy(), ori_size)\n",
        "        heatmap = (cm.jet(temp_cam)[..., :3] * 255).astype(\"uint8\")\n",
        "        temp_cam = (img * 0.5 + heatmap * 0.5).astype(\"uint8\")\n",
        "\n",
        "        return temp_cam, predict_cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TdYQHqVwy3E"
      },
      "outputs": [],
      "source": [
        "def save_grad_cam(model, target_layer, img_list, weight_file, save_path, args):\n",
        "    # if save_path == img_root:\n",
        "    #     raise ValueError(\"Save path should not be the same with image root, \" \n",
        "    #                      \"otherwise the original data will be overwritten\")\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Define the model and grad cam instance\n",
        "    new_model = model.clone()\n",
        "    new_model.load_state_dict(torch.load(weight_file))\n",
        "    grad_cam = GradCAM(new_model, target_layer, args.crop_size)\n",
        "\n",
        "    for img_path in tqdm(img_list):\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Get grad cam image and save it\n",
        "        res, pred = grad_cam(img, args.device)\n",
        "        cv2.imwrite(f\"{save_path}/{pred}_{os.path.basename(img_path)}\", res)\n",
        "\n",
        "    grad_cam.remove_handlers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGVd15_6vstP",
        "outputId": "4f7f937b-0858-48fb-a1e7-6880997dc8ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 389/389 [00:21<00:00, 18.15it/s]\n"
          ]
        }
      ],
      "source": [
        "save_grad_cam(\n",
        "    model=train_model, target_layer=\"model.layer4.2.conv2\",\n",
        "    img_list=val_yes_defect + val_no_defect, \n",
        "    weight_file=\"best.pt\", save_path=\"cam_image\",\n",
        "    args=args\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDOVGtM3R4mG"
      },
      "outputs": [],
      "source": [
        "# Save weights\n",
        "os.makedirs(\"drive/MyDrive/material\", exist_ok=True)\n",
        "!cp {best,cur,last}.pt drive/MyDrive/material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaB2-i-pbHXf"
      },
      "source": [
        "## ONNX\n",
        "\n",
        "| model |  time |\n",
        "|: --- :|: --- :|\n",
        "| torch | 0.253 |\n",
        "| onnx  | 0.037 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66kXQ1ocdXid",
        "outputId": "f442ae02-1408-49b5-b9fe-018bec2447b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Installing collected packages: onnxruntime, onnx\n",
            "Successfully installed onnx-1.11.0 onnxruntime-1.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLd2B4r1dqM0"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVaIsrfbT5CY"
      },
      "outputs": [],
      "source": [
        "# Transform the pytorch model to onnx\n",
        "dummy_input = torch.randn(1, 3, 352, 352, device=\"cuda\")\n",
        "\n",
        "input_names = [\"input\"]\n",
        "output_names = [\"output\"]\n",
        "\n",
        "train_model.load_state_dict(torch.load(\"best.pt\"))\n",
        "train_model.eval()\n",
        "torch.onnx.export(train_model, dummy_input, \"resnet.onnx\",\n",
        "                  input_names=input_names, output_names=output_names,\n",
        "                  opset_version=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmdjNGdeb8ZG"
      },
      "outputs": [],
      "source": [
        "# Load the ONNX model\n",
        "model = onnx.load(\"resnet.onnx\")\n",
        "\n",
        "# Check that the model is well formed\n",
        "onnx.checker.check_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neDfM2ZWd0vz"
      },
      "outputs": [],
      "source": [
        "# Check accuracy of ONNX model\n",
        "\n",
        "# Load model\n",
        "ort_session = ort.InferenceSession(\"resnet.onnx\")\n",
        "\n",
        "total_correct = []\n",
        "total_predict = []\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((args.size, args.size)),\n",
        "    transforms.CenterCrop((args.crop_size, args.crop_size)),\n",
        "    transforms.Normalize(mean=args.mean, std=args.std),\n",
        "    transforms.Lambda(lambda x: x.unsqueeze(0).numpy())\n",
        "])\n",
        "\n",
        "ground_truth = [1] * len(val_yes_defect) + [0] * len(val_no_defect)\n",
        "for label, img_path in zip(ground_truth, val_yes_defect + val_no_defect):\n",
        "    # Read in image\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    outputs = ort_session.run(None, {\"input\": img_transform(img)})\n",
        "    \n",
        "    total_correct.append(label)\n",
        "    total_predict.append(int(outputs[0][0][1] > outputs[0][0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDUsCoepfXF9",
        "outputId": "959f8700-4664-42b9-9922-da3344b79b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX, accuracy: 1.0 f1_score: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"ONNX, accuracy: {accuracy_score(total_correct, total_predict)} \"\n",
        "      f\"f1_score: {f1_score(total_correct, total_predict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br6ldrLJiRrV"
      },
      "outputs": [],
      "source": [
        "# Save onnx file\n",
        "!cp resnet.onnx drive/MyDrive/material  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbdOb1PVP_P-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Meta_3D_printer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
