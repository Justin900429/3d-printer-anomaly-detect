{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantization Aware Training\n",
        "* [dataset](https://www.kaggle.com/datasets/justin900429/3d-printer-defected-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGBnIIFEbTZv",
        "outputId": "872d3e04-97c4-44ca-a280-426fef399723"
      },
      "outputs": [],
      "source": [
        "# Use my own version of timm to support quantized option\n",
        "!pip install git+https://github.com/Justin900429/pytorch-image-models.git\n",
        "!pip install gdown==4.4.0\n",
        "!gdown 1Fq0DkvzoB3wI6a8IgPeYplD01c-WmXvn -O tmp.zip && unzip -q tmp.zip && rm tmp.zip\n",
        "!gdown 1-5w5uWGPVL43a2xkFHRI6WY5KPak_ZHQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rXyhn8OVcEyJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm \n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxX8UpdncKLV"
      },
      "source": [
        "## Create training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "67qbj7ZOcLG6"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "\n",
        "# Set up training dataset\n",
        "train_no_defect = [\n",
        "    file for file in glob.glob(\"no_defected/*.jpg\") if \"scratch_2\" not in file]\n",
        "train_yes_defect = [\n",
        "    file for file in glob.glob(\"defected/*.jpg\") if \"no_bottom\" not in file\n",
        "]\n",
        "train_yes_defect = random.choices(train_yes_defect, k=len(train_no_defect))\n",
        "\n",
        "# Set up validation dataset\n",
        "val_no_defect = [\n",
        "    file for file in glob.glob(\"no_defected/*.jpg\") if \"scratch_2\" in file]\n",
        "val_yes_defect = [\n",
        "    file for file in glob.glob(\"defected/*.jpg\") if \"no_bottom\" in file]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNPBjUhgosve"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qsJKpAIPouPy"
      },
      "outputs": [],
      "source": [
        "class ListDataset(Dataset):\n",
        "    def __init__(self, yes_defect, no_defect, transform=None):\n",
        "        self.img_list = yes_defect + no_defect\n",
        "        self.label = [1] * len(yes_defect) + [0] * len(no_defect)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_list[idx])\n",
        "        label = self.label[idx]\n",
        "        img = self.transform(img)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A9jBPZyHou8C"
      },
      "outputs": [],
      "source": [
        "def make_loader(yes_defect, no_defect, transform, batch_size,\n",
        "                shuffle=True, num_workers=2, pin_memory=True,\n",
        "                train=True):\n",
        "    dataset = ListDataset(\n",
        "        yes_defect=yes_defect, no_defect=no_defect, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        dataset, batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=pin_memory)\n",
        "    \n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yeY7SR9kow87"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_predict = []\n",
        "    total_ground_truth = []\n",
        "    for data, label in val_loader:\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        prediction = output.argmax(dim=-1)\n",
        "\n",
        "        total_predict.extend(prediction.cpu().tolist())\n",
        "        total_ground_truth.extend(label.cpu().tolist())\n",
        "\n",
        "    return accuracy_score(total_ground_truth, total_predict), \\\n",
        "           f1_score(total_ground_truth, total_predict, average=\"macro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lLIMbOD2oynP"
      },
      "outputs": [],
      "source": [
        "def quantize_train(model, train_loader, val_loader, criterion, optimizer, args):\n",
        "    best_f1 = 0\n",
        "    model.apply(torch.ao.quantization.enable_observer)\n",
        "    model.apply(torch.ao.quantization.enable_fake_quant)\n",
        "    for epoch in range(args.epochs):\n",
        "        train_progress_bar = tqdm(\n",
        "            train_loader, desc=f\"Epochs: {epoch + 1}/{args.epochs}\")\n",
        "        \n",
        "        model.train()\n",
        "        for data, label in train_progress_bar:\n",
        "            data = data.to(args.device)\n",
        "            label = label.to(args.device)\n",
        "\n",
        "            # Send data into the model and compute the loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            # Update the model with back propagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Obtain the quantization model for evaluation\n",
        "        quantized_model = torch.ao.quantization.convert(\n",
        "            copy.deepcopy(model).cpu().eval(), inplace=False)\n",
        "\n",
        "        # Compute the accuracy ans save the best model\n",
        "        eval_acc, eval_f1 = evaluate(\n",
        "            quantized_model, val_loader, \"cpu\")\n",
        "        print(f\"Validation accuracy: {eval_acc:.8f} f1-score: {eval_f1:.8f}\")\n",
        "        if eval_f1 > best_f1:\n",
        "            best_f1 = eval_f1\n",
        "            torch.save(model.state_dict(), \"best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nl8ZsmIb8dQS"
      },
      "outputs": [],
      "source": [
        "def get_quantized_model_from_weight(model, weight=\"best.pt\"):\n",
        "    new_model = copy.deepcopy(model).cpu().eval()\n",
        "    new_model.load_state_dict(torch.load(weight, map_location=\"cpu\"))\n",
        "    quantized_model = torch.quantization.convert(new_model, inplace=False)\n",
        "    return quantized_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_PEZqoWcVf7"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GS-mf_HLcLa4"
      },
      "outputs": [],
      "source": [
        "class QuantizeTrainModel(nn.Module):\n",
        "    def __init__(self, model_name=\"resnet34\", pretrained=True, num_classes=2):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Model settings\n",
        "        self.model_name = model_name\n",
        "        self.pretrained=pretrained\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Floating point -> Integer for input\n",
        "        self.quant = torch.ao.quantization.QuantStub()\n",
        "\n",
        "        # Check out the doc: https://rwightman.github.io/pytorch-image-models/\n",
        "        #  for different models\n",
        "        self.model = timm.create_model(\n",
        "            model_name, pretrained=pretrained, \n",
        "            block_args={\"use_quantized\": True})\n",
        "        \n",
        "        # Change the output linear layers to fit the output classes\n",
        "        self.model.fc = nn.Linear(\n",
        "            self.model.fc.weight.shape[1],\n",
        "            num_classes\n",
        "        )\n",
        "\n",
        "        # Integer to Floating point for output\n",
        "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.model(x)\n",
        "        return self.dequant(x)\n",
        "\n",
        "    def clone(self):\n",
        "        clone = QuantizeTrainModel(self.model_name, self.pretrained, self.num_classes)\n",
        "        clone.load_state_dict(self.state_dict())\n",
        "        if self.is_cuda():\n",
        "            clone.cuda()\n",
        "        return clone\n",
        "    \n",
        "    def fused_module_inplace(self):\n",
        "        \"\"\"\n",
        "        Fusing the model for resnet family only. Print out the model architecture\n",
        "        to know how the logic works. Note that during the quantize fusion, \n",
        "        conv + bn + act or conv + bn should be bundled to together\n",
        "        \"\"\"\n",
        "        self.train()\n",
        "        \n",
        "        for module_name, module in self.named_children():\n",
        "            # This coding style should not be correct but the code can be\n",
        "            #  more readable\n",
        "            if \"model\" not in module_name:\n",
        "                continue\n",
        "            \n",
        "            torch.ao.quantization.fuse_modules_qat(\n",
        "                module, [[\"conv1\", \"bn1\", \"act1\"]], inplace=True\n",
        "            )\n",
        "            for basic_block_name, basic_block in module.named_children():\n",
        "                # Same as above reason :)\n",
        "                if \"layer\" not in basic_block_name:\n",
        "                    continue\n",
        "\n",
        "                for sub_block_name, sub_block in basic_block.named_children():\n",
        "                    torch.ao.quantization.fuse_modules_qat(\n",
        "                        sub_block, \n",
        "                        [[\"conv1\", \"bn1\", \"act1\"], [\"conv2\", \"bn2\", \"act2\"]],\n",
        "                        inplace=True\n",
        "                    )\n",
        "                    for sub_sub_block_name, sub_sub_block in sub_block.named_children():\n",
        "                        if sub_block_name == \"downsample\":\n",
        "                            torch.ao.quantization.fuse_modules_qat(\n",
        "                                sub_block, [[\"0\", \"1\"]], inplace=True\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HEQtZ5lUqcEX"
      },
      "outputs": [],
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"tmp.pt\")\n",
        "    print(\"Size (MB):\", os.path.getsize(\"tmp.pt\") / 1e6)\n",
        "    os.remove(\"tmp.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J6mUcZ_nPIr"
      },
      "source": [
        "## Quantized awared training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JCG2qTDVnUwi"
      },
      "outputs": [],
      "source": [
        "class args:\n",
        "    # Training\n",
        "    epochs = 30\n",
        "    batch_size = 32\n",
        "    lr = 3e-4\n",
        "    weight_decay=1e-5\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Transform\n",
        "    size = 400\n",
        "    crop_size = 352\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i0exvp42o_Eh"
      },
      "outputs": [],
      "source": [
        "# Set up train loader and test loader\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((args.size, args.size)),\n",
        "    transforms.CenterCrop((args.crop_size, args.crop_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Normalize(mean=args.mean, std=args.std)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                                    \n",
        "    transforms.Resize((args.size, args.size)),\n",
        "    transforms.CenterCrop((args.crop_size, args.crop_size)),\n",
        "    transforms.Normalize(mean=args.mean, std=args.std)\n",
        "])\n",
        "\n",
        "train_loader = make_loader(\n",
        "    yes_defect=train_yes_defect, no_defect=train_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=train_transform)\n",
        "val_loader = make_loader(\n",
        "    yes_defect=val_yes_defect, no_defect=val_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=val_transform, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vv1vX3zkpkIg"
      },
      "outputs": [],
      "source": [
        "train_loader = make_loader(\n",
        "    yes_defect=train_yes_defect, no_defect=train_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=train_transform)\n",
        "val_loader = make_loader(\n",
        "    yes_defect=val_yes_defect, no_defect=val_no_defect,\n",
        "    batch_size=args.batch_size,\n",
        "    transform=val_transform, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fWEJG1Bh6UP"
      },
      "outputs": [],
      "source": [
        "model = QuantizeTrainModel().to(args.device)\n",
        "model.load_state_dict(torch.load(\"cur.pt\", map_location=args.device))\n",
        "model.fused_module_inplace()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set up quantization config to fbgemm\n",
        "# See more: https://github.com/pytorch/FBGEMM\n",
        "model.qconfig = torch.ao.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
        "# Shiftign to train model is required for quantization training\n",
        "model.train()\n",
        "torch.ao.quantization.prepare_qat(model, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6_YWNVMEADV",
        "outputId": "804ce627-0703-4736-8ace-f575eaba46c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size (MB): 21.538525\n"
          ]
        }
      ],
      "source": [
        "quantized_model = get_quantized_model_from_weight(model)\n",
        "print_size_of_model(quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhH3MuUD6-hf"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1PHRov2qjSc",
        "outputId": "641b700e-b7b4-4755-eebe-18d8540e3f4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 1/30: 100%|██████████| 32/32 [00:11<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.97943445 f1-score: 0.97152686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 2/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.99485861 f1-score: 0.99313303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 3/30: 100%|██████████| 32/32 [00:11<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.99742931 f1-score: 0.99655463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 4/30: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 5/30: 100%|██████████| 32/32 [00:11<00:00,  2.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 6/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 7/30: 100%|██████████| 32/32 [00:11<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 8/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 9/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 10/30: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 11/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 12/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 13/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.99742931 f1-score: 0.99655463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 14/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 15/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 16/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 17/30: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 18/30: 100%|██████████| 32/32 [00:11<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 19/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 20/30: 100%|██████████| 32/32 [00:11<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 21/30: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 22/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 23/30: 100%|██████████| 32/32 [00:11<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 24/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 25/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 26/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 27/30: 100%|██████████| 32/32 [00:11<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 28/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 29/30: 100%|██████████| 32/32 [00:11<00:00,  2.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 30/30: 100%|██████████| 32/32 [00:11<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.00000000 f1-score: 1.00000000\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "quantize_train(model, train_loader, val_loader, criterion, optimizer, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVX2BM8uMRej"
      },
      "source": [
        "## Save quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HTECwbNyETip"
      },
      "outputs": [],
      "source": [
        "quantized_model = get_quantized_model_from_weight(model)\n",
        "torch.save(quantized_model.state_dict(), \"quantized.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQnyniBcM_cM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantize.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
